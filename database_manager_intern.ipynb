{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert pdf to image from 27-50 page custom format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion completed!\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import os\n",
    "\n",
    "pdf_path = r'Documents\\Books.pdf'\n",
    "output_folder = r\"Image\"\n",
    "\n",
    "# Ensure output folder exists\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Open the PDF\n",
    "doc = fitz.open(pdf_path)\n",
    "\n",
    "# Convert first 20 pages to images\n",
    "# set here 27 to 47 for expected work to assignment \n",
    "for page_num in range(27,50):  # Ensure max pages don't exceed document length\n",
    "    page = doc.load_page(page_num)  # Load each page\n",
    "    pix = page.get_pixmap(dpi=300)  # Render as image\n",
    "    img_path = os.path.join(output_folder, f\"page_{page_num + 1}.jpg\")\n",
    "    \n",
    "    # Save as JPG\n",
    "    pix.save(img_path, \"jpeg\")\n",
    "\n",
    "print(\"Conversion completed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OCR (Image to Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "# Folder containing images\n",
    "image_folder = \"Image/\"\n",
    "output_text_file = \"docs/output.txt\"\n",
    "\n",
    "\n",
    "def process_image(img_path):\n",
    "    text = reader.readtext(img_path, detail=0)\n",
    "    return f\"--- Text from {img_path} ---\\n{' '.join(text)}\\n\\n\"\n",
    "\n",
    "# Get all images\n",
    "image_paths = [os.path.join(image_folder, f) for f in os.listdir(image_folder) if f.endswith((\".png\", \".jpg\", \".jpeg\"))]\n",
    "\n",
    "# Use multiprocessing\n",
    "with multiprocessing.Pool(processes=multiprocessing.cpu_count()) as pool:\n",
    "    results = pool.map(process_image, image_paths)\n",
    "\n",
    "# Save results\n",
    "with open(output_text_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.writelines(results)\n",
    "\n",
    "print(f\"Text extracted and saved to {output_text_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-docx in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.1.2)\n",
      "Requirement already satisfied: lxml>=3.1.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-docx) (5.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-docx) (4.12.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install python-docx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here Extract data from Image and Convert to docs file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted text saved: Extracted_Docs\\page_27.docx\n",
      "Extracted text saved: Extracted_Docs\\page_28.docx\n",
      "Extracted text saved: Extracted_Docs\\page_29.docx\n",
      "Extracted text saved: Extracted_Docs\\page_30.docx\n",
      "Extracted text saved: Extracted_Docs\\page_31.docx\n",
      "Extracted text saved: Extracted_Docs\\page_32.docx\n",
      "Extracted text saved: Extracted_Docs\\page_33.docx\n",
      "Extracted text saved: Extracted_Docs\\page_34.docx\n",
      "Extracted text saved: Extracted_Docs\\page_35.docx\n",
      "Extracted text saved: Extracted_Docs\\page_36.docx\n",
      "Extracted text saved: Extracted_Docs\\page_37.docx\n",
      "Extracted text saved: Extracted_Docs\\page_38.docx\n",
      "Extracted text saved: Extracted_Docs\\page_39.docx\n",
      "Extracted text saved: Extracted_Docs\\page_40.docx\n",
      "Extracted text saved: Extracted_Docs\\page_41.docx\n",
      "Extracted text saved: Extracted_Docs\\page_42.docx\n",
      "Extracted text saved: Extracted_Docs\\page_43.docx\n",
      "Extracted text saved: Extracted_Docs\\page_44.docx\n",
      "Extracted text saved: Extracted_Docs\\page_45.docx\n",
      "Extracted text saved: Extracted_Docs\\page_46.docx\n",
      "Extracted text saved: Extracted_Docs\\page_47.docx\n",
      "Extracted text saved: Extracted_Docs\\page_48.docx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "from docx import Document\n",
    "\n",
    "# Set Tesseract OCR path (Only needed if not in system PATH)\n",
    "# Here I set this manually so that I don't need to add this in Environment path \n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "def convert_images_to_docs(folder_path, output_folder):\n",
    "    # Create output folder if it doesn't exist\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Supported image extensions\n",
    "    image_extensions = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tiff\")\n",
    "\n",
    "    # Loop through all files in the folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.lower().endswith(image_extensions):\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "\n",
    "            try:\n",
    "                image = Image.open(image_path)  # Open image\n",
    "                text = pytesseract.image_to_string(image, lang=\"ben\")  # Extract Bangla text\n",
    "\n",
    "                # Save the extracted text to a .docx file\n",
    "                doc_filename = os.path.splitext(filename)[0] + \".docx\"  # Keep same name but .docx extension\n",
    "                doc_path = os.path.join(output_folder, doc_filename)\n",
    "\n",
    "                doc = Document()\n",
    "                doc.add_paragraph(text.strip())  # Add extracted text to the document\n",
    "                doc.save(doc_path)  # Save document\n",
    "\n",
    "                print(f\"Extracted text saved: {doc_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\" Error processing {filename}: {e}\")\n",
    "\n",
    "# Example Usage\n",
    "input_folder = r\"Image\"  # Folder containing images\n",
    "output_folder = r\"Extracted_Docs\"  # Folder to save .docx files\n",
    "\n",
    "convert_images_to_docs(input_folder, output_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here merged all docs file into one single docs file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Merged document saved as: Final_Merged_Document.docx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from docx import Document\n",
    "\n",
    "def merge_docs(input_folder, output_file):\n",
    "    \"\"\" Merge all .docx files in a folder into a single document (without extra headings) \"\"\"\n",
    "    merged_doc = Document()\n",
    "    \n",
    "    # Get all .docx files from the folder\n",
    "    doc_files = sorted([f for f in os.listdir(input_folder) if f.endswith(\".docx\")])\n",
    "\n",
    "    if not doc_files:\n",
    "        print(\"No .docx files found in the folder!\")\n",
    "        return\n",
    "    \n",
    "    for doc_file in doc_files:\n",
    "        doc_path = os.path.join(input_folder, doc_file)\n",
    "        \n",
    "        try:\n",
    "            doc = Document(doc_path)\n",
    "            for para in doc.paragraphs:\n",
    "                merged_doc.add_paragraph(para.text)  # Add content without extra formatting\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error merging {doc_file}: {e}\")\n",
    "\n",
    "    # Save the merged document\n",
    "    merged_doc.save(output_file)\n",
    "    print(f\" Merged document saved as: {output_file}\")\n",
    "\n",
    "# Example Usage\n",
    "input_folder = r\"Extracted_Docs\"  # Folder containing multiple .docx files\n",
    "output_file = r\"Final_Merged_Document.docx\"  # Output file name\n",
    "\n",
    "merge_docs(input_folder, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Merged Excel file created successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define chapter list (dictionary)\n",
    "chapter_list = {\n",
    "    1: \"পিতা-মাতার সাথে সদ্ব্যবহার\"\n",
    "}\n",
    "\n",
    "# Define section list (dictionary)\n",
    "section_list = {\n",
    "    1: \"আমি মানুষকে তার পিতা-মাতার সাথে সদ্ব্যবহারের নিদেশ প্রদান করেছি\",\n",
    "    2: \"মায়ের সাথে সদাচরণ\",\n",
    "    3: \"বাবার সাথে সদাচরণ\",\n",
    "    4: \"পিতা-মাতা অত্যাচার করলেও তাদের সাথে সদাচরণ করা\",\n",
    "    5: \"মাতা-পিতার সাথে নরম সুরে কথা বলা\",\n",
    "    6: \"পিতা-মাতার অবাধ্য হওয়ার পরিণতি\",\n",
    "    7: \"যে পিতা-মাতাকে অভিশপ্ত করে আল্লাহ তাআলাও তাকে অভিশপ্ত করে\",\n",
    "    8: \"পাপ ব্যতীত পিতা-মাতার সব বিষয়ে আনুগত্য করতে হবে\",\n",
    "    9: \"যে ব্যক্তি পিতা-মাতাকে পেল কিন্তু জান্নাত অর্জন করতে পারেনি\",\n",
    "    10: \"যে তার পিতা-মাতার সাথে ভালো আচরণ করবে আল্লাহ তার আয়ু বৃদ্ধি করেন\",\n",
    "    11: \"অমুসলিম পিতার জন্য কেউ যেন ক্ষমা প্রার্থনা না করে\",\n",
    "    12: \"অমুসলিম পিতার সাথেও সদাচরণ করা আবশ্যক\",\n",
    "    13: \"পিতা-মাতাকে গালি না দেয়া\",\n",
    "    14: \"পিতা-মাতার অবাধ্য হওয়ার শান্তি\",\n",
    "    15: \"পিতা-মাতার ক্রন্দন\",\n",
    "    16: \"মাতা-পিতার দুআ\",\n",
    "    17: \"খ্রিষ্টান মা-কে ইসলামের দাওয়াত দেয়া\",\n",
    "    18: \"পিতা-মাতার মৃত্যুর পরে তাদের সাথে সদাচার করা\",\n",
    "}\n",
    "\n",
    "# Convert dictionaries into pandas DataFrames\n",
    "df_chapters = pd.DataFrame(list(chapter_list.items()), columns=[\"Chapter ID\", \"Chapter Title\"])\n",
    "df_sections = pd.DataFrame(list(section_list.items()), columns=[\"Section ID\", \"Section Title\"])\n",
    "\n",
    "# Write both DataFrames into separate sheets in an Excel file\n",
    "output_file = \"merged_chapter_section.xlsx\"\n",
    "with pd.ExcelWriter(output_file, engine=\"openpyxl\") as writer:\n",
    "    df_chapters.to_excel(writer, sheet_name=\"Chapters\", index=False)\n",
    "    df_sections.to_excel(writer, sheet_name=\"Sections\", index=False)\n",
    "\n",
    "print(\" Merged Excel file created successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here Extract only Hadith , where remove the Chapter and Section from docs file handle the ambiguous issue "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel file created successfully!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from docx import Document\n",
    "\n",
    "def bengali_to_int(bengali_num):\n",
    "    \"\"\"Convert Bengali numerals to integer.\"\"\"\n",
    "    digits = {'০': '0', '১': '1', '২': '2', '৩': '3', '৪': '4',\n",
    "              '৫': '5', '৬': '6', '৭': '7', '৮': '8', '৯': '9'}\n",
    "    return int(''.join(digits[c] for c in bengali_num))\n",
    "\n",
    "def extract_text_from_docx(docx_path):\n",
    "    \"\"\"Extracts text from a .docx file.\"\"\"\n",
    "    doc = Document(docx_path)\n",
    "    return \"\\n\".join([para.text for para in doc.paragraphs])\n",
    "\n",
    "# Read text from DOCX instead of plain text file\n",
    "docx_path = \"Only_Hadith_Documents.docx\"\n",
    "text = extract_text_from_docx(docx_path)\n",
    "\n",
    "entries = []\n",
    "current_id = None\n",
    "current_content = []\n",
    "\n",
    "# Split text into lines and process each line\n",
    "lines = text.split('\\n')\n",
    "for line in lines:\n",
    "    stripped_line = line.strip()\n",
    "    # Check if the line starts with a Bengali numeral ID (e.g., [১])\n",
    "    id_match = re.match(r'^\\[([০-৯]+)\\]', stripped_line)\n",
    "    if id_match:\n",
    "        if current_id is not None:\n",
    "            # Save the previous entry\n",
    "            entries.append({\n",
    "                'id': current_id,\n",
    "                'hadith_title': ' '.join(current_content).strip()\n",
    "            })\n",
    "            current_content = []\n",
    "        # Convert Bengali numeral to integer for ID\n",
    "        current_id = bengali_to_int(id_match.group(1))\n",
    "        # Add the rest of the line (after the ID) to content\n",
    "        content_part = stripped_line.replace(id_match.group(0), '').strip()\n",
    "        if content_part:\n",
    "            current_content.append(content_part)\n",
    "    else:\n",
    "        if stripped_line:\n",
    "            current_content.append(stripped_line)\n",
    "\n",
    "# Add the last entry\n",
    "if current_id is not None:\n",
    "    entries.append({\n",
    "        'id': current_id,\n",
    "        'hadith_title': ' '.join(current_content).strip()\n",
    "    })\n",
    "\n",
    "# Create DataFrame and export to Excel\n",
    "df = pd.DataFrame(entries)\n",
    "df.to_excel('only_hadith_data.xlsx', index=False, engine='openpyxl')\n",
    "\n",
    "print(\"Excel file created successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now Merge the file "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here Merge Both Excel file to One Excel file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged Excel file created successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "chapter_section_file = r'output_excel\\\\merged_chapter_section.xlsx'\n",
    "only_hadith_file = r'output_excel\\\\only_hadith_data.xlsx'\n",
    "\n",
    "\n",
    "\n",
    "df1= pd.read_excel(chapter_section_file,sheet_name=None)\n",
    "df2= pd.read_excel(only_hadith_file,sheet_name=None)\n",
    "\n",
    "# Merge by appending data\n",
    "merged_sheet = { **df1,**df2}\n",
    "\n",
    "\n",
    "# Create a new Excel file with merged sections\n",
    "output_file = 'final_merged_data.xlsx'\n",
    "\n",
    "\n",
    "# Write all merged sheets to a new Excel file\n",
    "with pd.ExcelWriter(output_file, engine=\"openpyxl\") as writer:\n",
    "    for sheet_name, df in merged_sheet.items():\n",
    "        df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "print(\"Merged Excel file created successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
